# 4-STARS: æ ¸å¿ƒç»„ä»¶ä¸å¼•æ“é›†åˆ

> **æ–‡æ¡£è·¯å¾„**: `D:/migration/MCM-Killer/architectures/v3-0-0/draft/VALUABLE/4-STARS/01_CORE_ENGINES.md`
> **æ˜Ÿçº§**: â­â­â­â­
> **æ¥æºæ–‡æ¡£**: `05_MMAgent_Core.md`, `06_MMAgent_Engine.md`
> **æºç è·¯å¾„**: `D:/migration/clean version/LLM-MM-Agent/MMAgent/core/`, `engine/`

---

## æ ¸å¿ƒèµ„äº§æ¦‚è§ˆ

### Core ç»„ä»¶ (5ä¸ª)

| ç»„ä»¶ | æ–‡ä»¶ | æ ¸å¿ƒåŠŸèƒ½ | è¿ç§»éš¾åº¦ |
|------|------|----------|----------|
| **Abduction Engine** | `abduction_engine.py` | æº¯å› æ¨ç† | é«˜ |
| **Red Team Critic** | `red_team_critic.py` | çº¢é˜Ÿæµ‹è¯• | ä¸­ |
| **Research Strategist** | `research_strategist.py` | ç ”ç©¶ç­–ç•¥ | é«˜ |
| **FSM** | `research_strategist_fsm.py` | çŠ¶æ€æœº | ä½ |
| **State Manager** | `state_manager.py` | çŠ¶æ€ç®¡ç† | ä½ |

### Engine ç»„ä»¶ (10ä¸ª)

| å¼•æ“ | æ–‡ä»¶ | æ ¸å¿ƒåŠŸèƒ½ | è¿ç§»éš¾åº¦ |
|------|------|----------|----------|
| **Chart Renderer** | `chart_renderer.py` | å›¾è¡¨æ¸²æŸ“ | ä¸­ |
| **Diagram Engine** | `diagram_engine.py` | å›¾è¡¨ç”Ÿæˆ | ä¸­ |
| **Feature Engineer** | `feature_engineer.py` | ç‰¹å¾å·¥ç¨‹ | é«˜ |
| **Knowledge Retriever** | `knowledge_retriever.py` | çŸ¥è¯†æ£€ç´¢ | é«˜ |
| **Model Arena** | `model_arena.py` | æ¨¡å‹å¯¹æ¯” | ä¸­ |
| **Robustness Tester** | `robustness_tester.py` | é²æ£’æ€§æµ‹è¯• | ä¸­ |
| **Scientific Renderer** | `scientific_renderer.py` | ç§‘å­¦æ¸²æŸ“ | ä½ |
| **Sensitivity Analyzer** | `sensitivity_analyzer.py` | æ•æ„Ÿåº¦åˆ†æ | é«˜ |
| **Sensitivity Engine** | `sensitivity_engine.py` | æ•æ„Ÿåº¦å¼•æ“ | é«˜ |
| **Validation Suite** | `validation_suite.py` | éªŒè¯å¥—ä»¶ | ä¸­ |

---

## 1. Abduction Engine (æº¯å› æ¨ç†å¼•æ“)

### ä¸ºä»€ä¹ˆæ˜¯ 4 æ˜Ÿï¼Ÿ

å®ç°äº†**æº¯å› æ¨ç†æ¨¡å¼**ï¼Œä»è§‚å¯Ÿç»“æœæ¨ç†æœ€å¯èƒ½çš„åŸå› ï¼Œé€‚ç”¨äºé”™è¯¯è¯Šæ–­ã€æ•…éšœæ’æŸ¥ç­‰åœºæ™¯ã€‚

```python
from typing import List, Dict, Tuple

class AbductionEngine:
    """
    æº¯å› æ¨ç†å¼•æ“: ä»è§‚å¯Ÿæ¨ç†åŸå› 

    å…¬å¼: Score = P(observations|hypothesis) Ã— P(hypothesis)
    """
    def __init__(self, knowledge_base):
        self.knowledge_base = knowledge_base

    def abduct(self, observations: Dict[str, Any]) -> List[Tuple[Dict, float]]:
        """
        æº¯å› æ¨ç†: æ‰¾åˆ°æœ€èƒ½è§£é‡Šè§‚å¯Ÿç»“æœçš„å‡è®¾

        Args:
            observations: è§‚å¯Ÿç»“æœ

        Returns:
            æŒ‰åˆ†æ•°æ’åºçš„å‡è®¾åˆ—è¡¨ [(hypothesis, score), ...]
        """
        # ç”Ÿæˆå€™é€‰å‡è®¾
        hypotheses = self._generate_hypotheses(observations)

        # è¯„ä¼°æ¯ä¸ªå‡è®¾
        scored_hypotheses = []
        for hypothesis in hypotheses:
            score = self._score_hypothesis(hypothesis, observations)
            scored_hypotheses.append((hypothesis, score))

        # æŒ‰åˆ†æ•°æ’åº
        scored_hypotheses.sort(key=lambda x: x[1], reverse=True)

        return scored_hypotheses

    def _score_hypothesis(self, hypothesis: Dict, observations: Dict) -> float:
        """è¯„ä¼°å‡è®¾è§£é‡ŠåŠ›"""
        # è®¡ç®—ä¼¼ç„¶æ€§
        likelihood = self._compute_likelihood(hypothesis, observations)

        # è®¡ç®—å…ˆéªŒæ¦‚ç‡
        prior = self._compute_prior(hypothesis)

        return likelihood * prior

    def _compute_likelihood(self, hypothesis: Dict, observations: Dict) -> float:
        """è®¡ç®—ä¼¼ç„¶æ€§ P(observations|hypothesis)"""
        # ç®€åŒ–å®ç°
        score = 0.0
        for key, value in observations.items():
            if key in hypothesis:
                if hypothesis[key] == value:
                    score += 1.0
        return score / len(observations)

    def _compute_prior(self, hypothesis: Dict) -> float:
        """è®¡ç®—å…ˆéªŒæ¦‚ç‡ P(hypothesis)"""
        # åŸºäºçŸ¥è¯†åº“
        return self.knowledge_base.get_prior(hypothesis)
```

**åº”ç”¨åœºæ™¯**:
- é”™è¯¯è¯Šæ–­: ä»é”™è¯¯ä¿¡æ¯æ¨ç†æ ¹æœ¬åŸå› 
- æ•…éšœæ’æŸ¥: ä»ç—‡çŠ¶æ¨ç†æ•…éšœç‚¹
- è°ƒè¯•è¾…åŠ©: ä»å´©æºƒä¿¡æ¯æ¨ç† bug ä½ç½®

---

## 2. Red Team Critic (çº¢é˜Ÿæ‰¹è¯„å®¶)

### ä¸ºä»€ä¹ˆæ˜¯ 4 æ˜Ÿï¼Ÿ

å®ç°äº†**çº¢é˜Ÿæµ‹è¯•æ¨¡å¼**ï¼Œä»æ”»å‡»è€…è§’åº¦è¯„ä¼°ç³»ç»Ÿè¾“å‡ºï¼Œå‘ç°æ½œåœ¨é—®é¢˜ã€‚

```python
class RedTeamCritic:
    """
    çº¢é˜Ÿæ‰¹è¯„å®¶: ä»æ”»å‡»è€…è§’åº¦è¯„ä¼°
    """
    def __init__(self, attack_scenarios: List[Dict]):
        self.attack_scenarios = attack_scenarios

    def critique(self, system_output: Dict) -> Dict:
        """
        è¯„ä¼°ç³»ç»Ÿè¾“å‡ºï¼Œå‘ç°æ½œåœ¨é—®é¢˜

        Returns:
            æ‰¹è¯„æŠ¥å‘Š
        """
        report = {
            'vulnerabilities': [],
            'weaknesses': [],
            'improvements': []
        }

        # æµ‹è¯•å„ç§æ”»å‡»åœºæ™¯
        for scenario in self.attack_scenarios:
            result = self._test_attack(system_output, scenario)
            if result['success']:
                report['vulnerabilities'].append(result)

        # è¯„ä¼°å¼±ç‚¹
        weaknesses = self._identify_weaknesses(system_output)
        report['weaknesses'] = weaknesses

        # æå‡ºæ”¹è¿›å»ºè®®
        improvements = self._suggest_improvements(system_output)
        report['improvements'] = improvements

        return report

    def _test_attack(self, output: Dict, scenario: Dict) -> Dict:
        """æµ‹è¯•ç‰¹å®šæ”»å‡»åœºæ™¯"""
        # å®ç°æ”»å‡»é€»è¾‘
        pass
```

**åº”ç”¨åœºæ™¯**:
- è´¨é‡è¯„ä¼°: ä»æ‰¹è¯„è§’åº¦è¯„ä¼°è¾“å‡º
- é£é™©è¯†åˆ«: å‘ç°æ½œåœ¨é—®é¢˜
- æ”¹è¿›å»ºè®®: æå‡ºä¼˜åŒ–æ–¹å‘

---

## 3. Research Strategist (ç ”ç©¶ç­–ç•¥å®¶)

### ä¸ºä»€ä¹ˆæ˜¯ 4 æ˜Ÿï¼Ÿ

å®ç°äº†**åŠ¨æ€ç­–ç•¥åˆ¶å®š**ï¼Œæ ¹æ®å½“å‰çŠ¶æ€å’Œç›®æ ‡åˆ¶å®šæœ€ä¼˜ç­–ç•¥ã€‚

```python
class ResearchStrategist:
    """
    ç ”ç©¶ç­–ç•¥å®¶: åŠ¨æ€ç­–ç•¥åˆ¶å®š
    """
    def __init__(self):
        self.strategies = []

    def plan_strategy(self, current_state: Dict, goal: Dict) -> List[Dict]:
        """
        åˆ¶å®šç­–ç•¥

        Args:
            current_state: å½“å‰çŠ¶æ€
            goal: ç›®æ ‡

        Returns:
            ç­–ç•¥æ­¥éª¤åˆ—è¡¨
        """
        # åˆ†æå·®è·
        gap = self._analyze_gap(current_state, goal)

        # åˆ¶å®šè®¡åˆ’
        plan = self._create_plan(gap)

        return plan

    def _analyze_gap(self, current: Dict, goal: Dict) -> Dict:
        """åˆ†æå½“å‰çŠ¶æ€ä¸ç›®æ ‡çš„å·®è·"""
        gap = {}
        for key in goal:
            if key not in current:
                gap[key] = goal[key]
            elif current[key] != goal[key]:
                gap[key] = goal[key] - current[key]
        return gap
```

**åº”ç”¨åœºæ™¯**:
- åŠ¨æ€è§„åˆ’: æ ¹æ®çŠ¶æ€è°ƒæ•´ç­–ç•¥
- èµ„æºåˆ†é…: ä¼˜åŒ–èµ„æºä½¿ç”¨
- ä»»åŠ¡è°ƒåº¦: åŠ¨æ€ä»»åŠ¡åˆ†é…

---

## 4. FSM (æœ‰é™çŠ¶æ€æœº)

### ä¸ºä»€ä¹ˆæ˜¯ 4 æ˜Ÿï¼Ÿ

å®ç°äº†**FSM æ¨¡å¼**ï¼Œç®¡ç†å¤æ‚æµç¨‹çš„ç»å…¸æ¨¡å¼ã€‚

```python
from enum import Enum

class State(Enum):
    INIT = 'init'
    RUNNING = 'running'
    PAUSED = 'paused'
    COMPLETED = 'completed'
    ERROR = 'error'

class FSM:
    """
    æœ‰é™çŠ¶æ€æœº
    """
    def __init__(self):
        self.state = State.INIT
        self.transitions = {
            State.INIT: [State.RUNNING, State.ERROR],
            State.RUNNING: [State.PAUSED, State.COMPLETED, State.ERROR],
            State.PAUSED: [State.RUNNING, State.ERROR],
            State.COMPLETED: [],
            State.ERROR: [State.INIT]
        }

    def transition(self, new_state: State) -> bool:
        """çŠ¶æ€è½¬ç§»"""
        if new_state in self.transitions[self.state]:
            self.state = new_state
            return True
        return False
```

**åº”ç”¨åœºæ™¯**:
- æµç¨‹æ§åˆ¶: ç®¡ç†å¤æ‚æµç¨‹
- çŠ¶æ€ç®¡ç†: è·Ÿè¸ªç³»ç»ŸçŠ¶æ€
- é”™è¯¯æ¢å¤: å®šä¹‰é”™è¯¯æ¢å¤æµç¨‹

---

## 5. Feature Engineer (ç‰¹å¾å·¥ç¨‹å¼•æ“)

### ä¸ºä»€ä¹ˆæ˜¯ 4 æ˜Ÿï¼Ÿ

å®ç°äº†**è‡ªåŠ¨ç‰¹å¾å·¥ç¨‹**ï¼Œæ•°æ®åˆ†æå’Œæœºå™¨å­¦ä¹ çš„åŸºç¡€ã€‚

```python
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, LabelEncoder

class FeatureEngineer:
    """
    ç‰¹å¾å·¥ç¨‹å¼•æ“
    """
    def __init__(self):
        self.scalers = {}
        self.encoders = {}

    def fit_transform(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ‹Ÿåˆå¹¶è½¬æ¢æ•°æ®"""
        # æ•°å€¼ç‰¹å¾æ ‡å‡†åŒ–
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        for col in numeric_cols:
            scaler = StandardScaler()
            df[col] = scaler.fit_transform(df[[col]])
            self.scalers[col] = scaler

        # ç±»åˆ«ç‰¹å¾ç¼–ç 
        categorical_cols = df.select_dtypes(include=['object']).columns
        for col in categorical_cols:
            encoder = LabelEncoder()
            df[col] = encoder.fit_transform(df[col])
            self.encoders[col] = encoder

        return df

    def transform(self, df: pd.DataFrame) -> pd.DataFrame:
        """è½¬æ¢æ–°æ•°æ®"""
        for col, scaler in self.scalers.items():
            df[col] = scaler.transform(df[[col]])

        for col, encoder in self.encoders.items():
            df[col] = encoder.transform(df[col])

        return df
```

**åº”ç”¨åœºæ™¯**:
- æ•°æ®é¢„å¤„ç†: æ ‡å‡†åŒ–ã€å½’ä¸€åŒ–
- ç‰¹å¾åˆ›å»º: äº¤äº’ç‰¹å¾ã€å¤šé¡¹å¼ç‰¹å¾
- ç‰¹å¾é€‰æ‹©: é€‰æ‹©æœ€é‡è¦çš„ç‰¹å¾

---

## 6. Knowledge Retriever (çŸ¥è¯†æ£€ç´¢å¼•æ“)

### ä¸ºä»€ä¹ˆæ˜¯ 4 æ˜Ÿï¼Ÿ

å®ç°äº†**æ™ºèƒ½çŸ¥è¯†æ£€ç´¢**ï¼Œä»å¤§å‹çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³å†…å®¹ã€‚

```python
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

class KnowledgeRetriever:
    """
    çŸ¥è¯†æ£€ç´¢å¼•æ“
    """
    def __init__(self, knowledge_base: List[Dict]):
        self.knowledge_base = knowledge_base
        self.embeddings = None
        self._build_index()

    def _build_index(self):
        """æ„å»ºå‘é‡ç´¢å¼•"""
        texts = [self._text_for_item(item) for item in self.knowledge_base]
        self.embeddings = self._get_embeddings(texts)

    def retrieve(self, query: str, top_k: int = 5) -> List[Dict]:
        """æ£€ç´¢ç›¸å…³çŸ¥è¯†"""
        query_embedding = self._get_embedding(query)

        # è®¡ç®—ç›¸ä¼¼åº¦
        similarities = cosine_similarity(
            query_embedding.reshape(1, -1),
            self.embeddings
        )[0]

        # è·å– top_k
        top_indices = np.argsort(similarities)[::-1][:top_k]

        return [self.knowledge_base[i] for i in top_indices]

    def _get_embedding(self, text: str) -> np.ndarray:
        """è·å–æ–‡æœ¬åµŒå…¥"""
        # ä½¿ç”¨ embedding æ¨¡å‹
        pass
```

**åº”ç”¨åœºæ™¯**:
- çŸ¥è¯†æ£€ç´¢: ä»çŸ¥è¯†åº“æ£€ç´¢ç›¸å…³å†…å®¹
- é—®ç­”ç³»ç»Ÿ: æ£€ç´¢ç›¸å…³ç­”æ¡ˆ
- æ¨è: æ¨èç›¸å…³å†…å®¹

---

## 7. Sensitivity Analyzer (æ•æ„Ÿåº¦åˆ†æå™¨)

### ä¸ºä»€ä¹ˆæ˜¯ 4 æ˜Ÿï¼Ÿ

å®ç°äº†**æ•æ„Ÿåº¦åˆ†æ**ï¼Œè¯„ä¼°æ¨¡å‹å¯¹å‚æ•°å˜åŒ–çš„æ•æ„Ÿç¨‹åº¦ã€‚

```python
class SensitivityAnalyzer:
    """
    æ•æ„Ÿåº¦åˆ†æå™¨
    """
    def analyze(self, model, params: Dict, baseline_result: Dict) -> Dict:
        """
        åˆ†æå‚æ•°æ•æ„Ÿåº¦

        Args:
            model: æ¨¡å‹
            params: å‚æ•°å­—å…¸
            baseline_result: åŸºçº¿ç»“æœ

        Returns:
            æ•æ„Ÿåº¦åˆ†ææŠ¥å‘Š
        """
        report = {}

        for param_name, param_value in params.items():
            # æ‰°åŠ¨å‚æ•°
            perturbed_values = self._perturb_param(param_value)

            # è¯„ä¼°å½±å“
            sensitivities = []
            for perturbed_value in perturbed_values:
                new_params = params.copy()
                new_params[param_name] = perturbed_value

                new_result = model(new_params)

                sensitivity = self._compute_sensitivity(baseline_result, new_result)
                sensitivities.append(sensitivity)

            # è®¡ç®—å¹³å‡æ•æ„Ÿåº¦
            report[param_name] = {
                'mean_sensitivity': np.mean(sensitivities),
                'max_sensitivity': np.max(sensitivities),
                'min_sensitivity': np.min(sensitivities)
            }

        return report

    def _perturb_param(self, value: float) -> List[float]:
        """æ‰°åŠ¨å‚æ•°"""
        perturbations = [0.9, 0.95, 1.05, 1.1]
        return [value * p for p in perturbations]

    def _compute_sensitivity(self, baseline: Dict, new_result: Dict) -> float:
        """è®¡ç®—æ•æ„Ÿåº¦"""
        # ç®€åŒ–å®ç°: ä½¿ç”¨ç»“æœå·®å¼‚çš„ç»å¯¹å€¼
        key = list(baseline.keys())[0]
        return abs(new_result[key] - baseline[key]) / abs(baseline[key])
```

**åº”ç”¨åœºæ™¯**:
- å‚æ•°è°ƒä¼˜: è¯†åˆ«æ•æ„Ÿå‚æ•°
- é²æ£’æ€§åˆ†æ: è¯„ä¼°æ¨¡å‹é²æ£’æ€§
- é£é™©è¯„ä¼°: è¯†åˆ«é«˜é£é™©å‚æ•°

---

## è¿ç§»ä»·å€¼

### ğŸ”´ P0 - å¿…é¡»è¿ç§»

- [ ] **Abduction Engine** - è¯Šæ–­åˆ†æ
- [ ] **FSM** - æµç¨‹æ§åˆ¶

### ğŸŸ¡ P1 - å¼ºçƒˆæ¨è

- [ ] **Red Team Critic** - è´¨é‡è¯„ä¼°
- [ ] **Feature Engineer** - ç‰¹å¾å·¥ç¨‹
- [ ] **Knowledge Retriever** - çŸ¥è¯†æ£€ç´¢
- [ ] **Sensitivity Analyzer** - æ•æ„Ÿåº¦åˆ†æ

### ğŸŸ¢ P2 - å¯é€‰è¿ç§»

- [ ] **Research Strategist** - åŠ¨æ€è§„åˆ’
- [ ] **State Manager** - çŠ¶æ€ç®¡ç†
- [ ] **Chart Renderer** - å›¾è¡¨æ¸²æŸ“
- [ ] **Model Arena** - æ¨¡å‹å¯¹æ¯”
- [ ] **Robustness Tester** - é²æ£’æ€§æµ‹è¯•
- [ ] **Validation Suite** - éªŒè¯å¥—ä»¶

---

## æ ¸å¿ƒåˆ›æ–°ç‚¹

### Core ç»„ä»¶

1. **æº¯å› æ¨ç†**: ä»è§‚å¯Ÿæ¨ç†åŸå› 
2. **çº¢é˜Ÿæµ‹è¯•**: ä»æ”»å‡»è€…è§’åº¦è¯„ä¼°
3. **åŠ¨æ€ç­–ç•¥**: æ ¹æ®çŠ¶æ€è°ƒæ•´ç­–ç•¥
4. **FSM æ¨¡å¼**: ç®¡ç†å¤æ‚æµç¨‹
5. **çŠ¶æ€ç®¡ç†**: è·Ÿè¸ªç³»ç»ŸçŠ¶æ€

### Engine ç»„ä»¶

1. **è‡ªåŠ¨ç‰¹å¾å·¥ç¨‹**: æ•°æ®é¢„å¤„ç†å’Œç‰¹å¾åˆ›å»º
2. **æ™ºèƒ½çŸ¥è¯†æ£€ç´¢**: å‘é‡ç›¸ä¼¼åº¦æ£€ç´¢
3. **æ•æ„Ÿåº¦åˆ†æ**: è¯„ä¼°å‚æ•°å½±å“
4. **æ¨¡å‹å¯¹æ¯”**: å¤šæ¨¡å‹æ€§èƒ½å¯¹æ¯”
5. **é²æ£’æ€§æµ‹è¯•**: å‹åŠ›æµ‹è¯•

---

## ä¸å…¶ä»–èµ„äº§çš„é›†æˆ

| èµ„äº§ | é›†æˆæ–¹å¼ |
|------|----------|
| **autofixer.py** (6-STARS) | Abduction Engine ç”¨äºé”™è¯¯è¯Šæ–­ |
| **hmml_embedding.py** (6-STARS) | Knowledge Retriever ä½¿ç”¨åµŒå…¥ |
| **data_manager.py** (5-STARS) | Feature Engineer å¤„ç†æ•°æ® |

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2026-01-24
