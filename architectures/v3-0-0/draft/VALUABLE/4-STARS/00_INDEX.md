# 4-STARS: é‡è¦ç»„ä»¶ç²¾é€‰

> **æ–‡æ¡£è·¯å¾„**: `D:/migration/MCM-Killer/architectures/v3-0-0/draft/VALUABLE/4-STARS/00_INDEX.md`
> **æ˜Ÿçº§**: â­â­â­â­
> **æ•°é‡**: 6 ä¸ªè¯¦ç»†æ–‡æ¡£
> **è¿ç§»ä»·å€¼**: å€¼å¾—å‚è€ƒå€Ÿé‰´

---

## è¯¦ç»†æ–‡æ¡£åˆ—è¡¨

### 01. æ ¸å¿ƒç»„ä»¶ä¸å¼•æ“é›†åˆ
**æ–‡ä»¶**: [`01_CORE_ENGINES.md`](01_CORE_ENGINES.md)

**å†…å®¹**: core/ (5ä¸ªç»„ä»¶), engine/ (10ä¸ªå¼•æ“)

**æ ¸å¿ƒåˆ›æ–°**:
- Abduction Engine - æº¯å› æ¨ç†
- Red Team Critic - çº¢é˜Ÿæµ‹è¯•
- Research Strategist - åŠ¨æ€è§„åˆ’
- FSM - çŠ¶æ€æœºç®¡ç†
- Feature Engineer - ç‰¹å¾å·¥ç¨‹
- Knowledge Retriever - çŸ¥è¯†æ£€ç´¢
- Sensitivity Analyzer - æ•æ„Ÿåº¦åˆ†æ

---

### 02. ç»Ÿä¸€ LLM æ¥å£
**æ–‡ä»¶**: [`02_UNIFIED_LLM.md`](02_UNIFIED_LLM.md)

**å†…å®¹**: llm/llm.py

**æ ¸å¿ƒåˆ›æ–°**:
- ç»Ÿä¸€æ¥å£æ”¯æŒ 10+ æ¨¡å‹
- çº¿ç¨‹é”é˜²æ­¢ Error 429
- Token ä½¿ç”¨è·Ÿè¸ª (LRU ç¼“å­˜)
- å¤šæä¾›å•†æ”¯æŒ (OpenAI, DeepSeek, GLM, Qwen)

---

### 03. Schema ç®¡ç†ä¸ä»£ç å®ˆå«
**æ–‡ä»¶**: [`03_SCHEMA_TOOLS.md`](03_SCHEMA_TOOLS.md)

**å†…å®¹**: schema/, code_guards, rate_limiter, schema_registryç­‰

**æ ¸å¿ƒåˆ›æ–°**:
- Schema Manager - é›†ä¸­å¼ç®¡ç†
- Code Guards - é¢„æ‰§è¡ŒéªŒè¯
- Rate Limiter - Singleton é€Ÿç‡é™åˆ¶
- Variable Contract - å¤šé˜¶æ®µä¸€è‡´æ€§

---

### 04. å™è¿°ç”Ÿæˆä¸æŠ¥å‘Šæ¨¡å—
**æ–‡ä»¶**: [`04_NARRATIVE_REPORTING.md`](04_NARRATIVE_REPORTING.md)

**å†…å®¹**: narrative/, reporting/

**æ ¸å¿ƒåˆ›æ–°**:
- Narrative Weaver - å™è¿°ç¼–ç»‡å™¨
- Academic Tools - å­¦æœ¯å†™ä½œå·¥å…·
- Critique Generator - æ‰¹è¯„ç”Ÿæˆå™¨
- Abstract Orchestrator - æ‘˜è¦ç¼–æ’å™¨

---

### 05. æ ¸å¿ƒå·¥å…·å¿«ç…§
**æ–‡ä»¶**: [`05_UTILITY_SNAPSHOT.md`](05_UTILITY_SNAPSHOT.md)

**å†…å®¹**: utils/ éƒ¨åˆ†æ ¸å¿ƒå·¥å…·

**æ ¸å¿ƒåˆ›æ–°**:
- Path Guard - è·¯å¾„ä¿æŠ¤
- Import Guard - ä¾èµ–æ§åˆ¶
- Execution FSM - çŠ¶æ€ç®¡ç†
- Safe Merge - æ•°æ®åˆå¹¶
- Failure Handler - å¤±è´¥å¤„ç†

---

### 06. åŸºç¡€è®¾æ–½ä¸ç›®å½•å¯¼èˆª
**æ–‡ä»¶**: [`06_INFRASTRUCTURE.md`](06_INFRASTRUCTURE.md)

**å†…å®¹**: 00_INDEX.md, MMBench/, evaluation/, test workplace/

**æ ¸å¿ƒåˆ›æ–°**:
- å®Œæ•´æ¶æ„å¯¼èˆª (22 æ–‡æ¡£)
- MMBench æ•°æ®é›† (111 é¢˜ç›®)
- ç‹¬ç«‹è¯„ä¼°æ¡†æ¶
- 35+ è‡ªåŠ¨åŒ–æµ‹è¯•

---

## 1. æ ¸å¿ƒ: æº¯å› æ¨ç†å¼•æ“ (abduction_engine.py)

### ä¸ºä»€ä¹ˆæ˜¯ 4 æ˜Ÿï¼Ÿ

å®ç°äº†**æº¯å› æ¨ç†æ¨¡å¼**ï¼Œå¯ä»¥ç”¨äºè¯Šæ–­åˆ†æã€æ ¹å› åˆ†æç­‰åœºæ™¯ã€‚

```python
class AbductionEngine:
    """
    æº¯å› æ¨ç†å¼•æ“: ä»è§‚å¯Ÿç»“æœæ¨ç†æœ€å¯èƒ½çš„åŸå› 

    Args:
        observations: è§‚å¯Ÿç»“æœ
        knowledge_base: çŸ¥è¯†åº“ (å¯èƒ½çš„å‡è®¾)
    """
    def __init__(self, knowledge_base):
        self.knowledge_base = knowledge_base

    def abduct(self, observations):
        """
        æº¯å› æ¨ç†: æ‰¾åˆ°æœ€èƒ½è§£é‡Šè§‚å¯Ÿç»“æœçš„å‡è®¾

        Returns:
            æœ€å¯èƒ½çš„å‡è®¾åˆ—è¡¨ï¼ŒæŒ‰æ¦‚ç‡æ’åº
        """
        # ç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„å‡è®¾
        hypotheses = self._generate_hypotheses(observations)

        # è¯„ä¼°æ¯ä¸ªå‡è®¾çš„è§£é‡ŠåŠ›
        scored_hypotheses = []
        for hypothesis in hypotheses:
            score = self._score_hypothesis(hypothesis, observations)
            scored_hypotheses.append((hypothesis, score))

        # æŒ‰åˆ†æ•°æ’åº
        scored_hypotheses.sort(key=lambda x: x[1], reverse=True)

        return scored_hypotheses

    def _generate_hypotheses(self, observations):
        """ç”Ÿæˆå¯èƒ½çš„å‡è®¾"""
        return self.knowledge_base.get_relevant_hypotheses(observations)

    def _score_hypothesis(self, hypothesis, observations):
        """
        è¯„ä¼°å‡è®¾çš„è§£é‡ŠåŠ›

        Score = P(observations|hypothesis) * P(hypothesis)
        """
        # è®¡ç®—ä¼¼ç„¶æ€§
        likelihood = self._compute_likelihood(hypothesis, observations)

        # è®¡ç®—å…ˆéªŒæ¦‚ç‡
        prior = self._compute_prior(hypothesis)

        return likelihood * prior
```

**åº”ç”¨åœºæ™¯**:
- é”™è¯¯è¯Šæ–­: ä»é”™è¯¯ä¿¡æ¯æ¨ç†æ ¹æœ¬åŸå› 
- æ•…éšœæ’æŸ¥: ä»ç—‡çŠ¶æ¨ç†æ•…éšœç‚¹
- è°ƒè¯•è¾…åŠ©: ä»å´©æºƒä¿¡æ¯æ¨ç† bug ä½ç½®

---

## 2. æ ¸å¿ƒ: çº¢é˜Ÿæ‰¹è¯„å®¶ (red_team_critic.py)

### ä¸ºä»€ä¹ˆæ˜¯ 4 æ˜Ÿï¼Ÿ

å®ç°äº†**çº¢é˜Ÿæµ‹è¯•æ¨¡å¼**ï¼Œå¯ä»¥ç”¨äºè´¨é‡è¯„ä¼°å’Œé£é™©è¯†åˆ«ã€‚

```python
class RedTeamCritic:
    """
    çº¢é˜Ÿæ‰¹è¯„å®¶: ä»æ”»å‡»è€…è§’åº¦è¯„ä¼°ç³»ç»Ÿ

    Args:
        system: å¾…è¯„ä¼°çš„ç³»ç»Ÿ
        attack_scenarios: æ”»å‡»åœºæ™¯åˆ—è¡¨
    """
    def __init__(self, attack_scenarios):
        self.attack_scenarios = attack_scenarios

    def critique(self, system_output):
        """
        è¯„ä¼°ç³»ç»Ÿè¾“å‡ºï¼Œå‘ç°æ½œåœ¨é—®é¢˜

        Returns:
            æ‰¹è¯„æŠ¥å‘Šï¼ŒåŒ…å«å‘ç°çš„é—®é¢˜
        """
        critique_report = {
            'vulnerabilities': [],
            'weaknesses': [],
            'improvements': []
        }

        # å°è¯•å„ç§æ”»å‡»åœºæ™¯
        for scenario in self.attack_scenarios:
            result = self._test_attack(system_output, scenario)
            if result['success']:
                critique_report['vulnerabilities'].append(result)

        # è¯„ä¼°å¼±ç‚¹
        weaknesses = self._identify_weaknesses(system_output)
        critique_report['weaknesses'] = weaknesses

        # æå‡ºæ”¹è¿›å»ºè®®
        improvements = self._suggest_improvements(system_output)
        critique_report['improvements'] = improvements

        return critique_report

    def _test_attack(self, system_output, scenario):
        """æµ‹è¯•ç‰¹å®šæ”»å‡»åœºæ™¯"""
        # å®ç°æ”»å‡»é€»è¾‘
        pass

    def _identify_weaknesses(self, system_output):
        """è¯†åˆ«ç³»ç»Ÿå¼±ç‚¹"""
        # å®ç°å¼±ç‚¹è¯†åˆ«
        pass

    def _suggest_improvements(self, system_output):
        """æå‡ºæ”¹è¿›å»ºè®®"""
        # å®ç°æ”¹è¿›å»ºè®®
        pass
```

**åº”ç”¨åœºæ™¯**:
- è´¨é‡è¯„ä¼°: ä»æ‰¹è¯„è§’åº¦è¯„ä¼°è¾“å‡º
- é£é™©è¯†åˆ«: å‘ç°æ½œåœ¨é—®é¢˜
- æ”¹è¿›å»ºè®®: æå‡ºä¼˜åŒ–æ–¹å‘

---

## 3. å¼•æ“: ç»Ÿä¸€ LLM æ¥å£ (llm.py)

### ä¸ºä»€ä¹ˆæ˜¯ 4 æ˜Ÿï¼Ÿ

å®ç°äº†**ç»Ÿä¸€ LLM æ¥å£**ï¼Œæ”¯æŒå¤šæ¨¡å‹ã€å¤šæä¾›å•†ï¼Œä½¿ç”¨çº¿ç¨‹é”é˜²æ­¢ Error 429ã€‚

```python
import threading

class LLM:
    """
    ç»Ÿä¸€ LLM æ¥å£

    æ”¯æŒçš„æä¾›å•†:
    - OpenAI: gpt-4o, gpt-4-turbo
    - DeepSeek: deepseek-chat
    - GLM: glm-4-flash, glm-4-plus
    - Qwen: qwen2.5-72b-instruct
    """
    def __init__(self, model_name, api_key, base_url=None):
        self.model_name = model_name
        self.api_key = api_key
        self.base_url = base_url

        # çº¿ç¨‹é”: é˜²æ­¢å¹¶å‘è°ƒç”¨å¯¼è‡´ Error 429
        self.lock = threading.Lock()

        # Token ä½¿ç”¨è·Ÿè¸ª
        self.usage_cache = LRUCache(maxsize=1000)

    def generate(self, prompt, system=None, temperature=0.7):
        """
        ç”Ÿæˆ LLM å“åº”

        Args:
            prompt: ç”¨æˆ·æç¤ºè¯
            system: ç³»ç»Ÿæç¤ºè¯
            temperature: æ¸©åº¦å‚æ•°

        Returns:
            LLM å“åº”
        """
        # åŠ é”: åºåˆ—åŒ–æ‰€æœ‰ API è°ƒç”¨
        with self.lock:
            # è°ƒç”¨ LLM API
            response = self._call_api(prompt, system, temperature)

            # è®°å½• Token ä½¿ç”¨
            self._track_usage(response)

            return response

    def _call_api(self, prompt, system, temperature):
        """è°ƒç”¨ LLM API"""
        # æ ¹æ® model_name é€‰æ‹©å¯¹åº”çš„ API
        if 'gpt' in self.model_name:
            return self._call_openai(prompt, system, temperature)
        elif 'deepseek' in self.model_name:
            return self._call_deepseek(prompt, system, temperature)
        elif 'glm' in self.model_name:
            return self._call_glm(prompt, system, temperature)
        elif 'qwen' in self.model_name:
            return self._call_qwen(prompt, system, temperature)
        else:
            raise ValueError(f"Unsupported model: {self.model_name}")

    def _track_usage(self, response):
        """è®°å½• Token ä½¿ç”¨"""
        prompt_tokens = response['usage']['prompt_tokens']
        completion_tokens = response['usage']['completion_tokens']
        total_tokens = response['usage']['total_tokens']

        self.usage_cache[self.model_name] = {
            'prompt_tokens': prompt_tokens,
            'completion_tokens': completion_tokens,
            'total_tokens': total_tokens
        }
```

**å…³é”®è®¾è®¡**:
1. **çº¿ç¨‹é”**: `self.lock = threading.Lock()` é˜²æ­¢å¹¶å‘è°ƒç”¨
2. **å¤šæ¨¡å‹æ”¯æŒ**: ç»Ÿä¸€æ¥å£æ”¯æŒ 10+ æ¨¡å‹
3. **Token è·Ÿè¸ª**: `LRUCache` è®°å½•ä½¿ç”¨æƒ…å†µ
4. **é”™è¯¯å¤„ç†**: ç»Ÿä¸€çš„é”™è¯¯å¤„ç†å’Œé‡è¯•

**è¿ç§»ä»·å€¼**:
- **é˜² Error 429**: çº¿ç¨‹é”åºåˆ—åŒ–æ‰€æœ‰ API è°ƒç”¨
- **å¤šæ¨¡å‹**: å¯ä»¥è½»æ¾åˆ‡æ¢ä¸åŒæ¨¡å‹
- **æˆæœ¬æ§åˆ¶**: Token è·Ÿè¸ªå¸®åŠ©æ§åˆ¶æˆæœ¬

---

## 4. å·¥å…·: é€Ÿç‡é™åˆ¶å™¨ (rate_limiter.py)

### ä¸ºä»€ä¹ˆæ˜¯ 4 æ˜Ÿï¼Ÿ

å®ç°äº† **Singleton æ¨¡å¼** çš„é€Ÿç‡é™åˆ¶å™¨ï¼Œé˜²æ­¢ API é€Ÿç‡é™åˆ¶é—®é¢˜ã€‚

```python
import time
import threading
from collections import deque

class RateLimiter:
    """
    é€Ÿç‡é™åˆ¶å™¨: Singleton æ¨¡å¼

    é™åˆ¶: æ¯åˆ†é’Ÿæœ€å¤š 60 ä¸ªè¯·æ±‚
    """
    _instance = None
    _lock = threading.Lock()

    def __new__(cls, requests_per_minute=60):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
                    cls._instance._initialize(requests_per_minute)
        return cls._instance

    def _initialize(self, requests_per_minute):
        self.requests_per_minute = requests_per_minute
        self.interval = 60 / requests_per_minute
        self.timestamps = deque()
        self.semaphore = threading.Semaphore(requests_per_minute)

    def acquire(self):
        """
        è·å–è®¸å¯ï¼Œå¦‚æœè¶…è¿‡é€Ÿç‡é™åˆ¶åˆ™ç­‰å¾…

        Returns:
            True å¦‚æœè·å¾—è®¸å¯
        """
        with self.semaphore:
            # ç§»é™¤è¿‡æœŸçš„è¯·æ±‚æ—¶é—´æˆ³
            now = time.time()
            while self.timestamps and self.timestamps[0] < now - 60:
                self.timestamps.popleft()

            # å¦‚æœè¾¾åˆ°é™åˆ¶ï¼Œç­‰å¾…
            if len(self.timestamps) >= self.requests_per_minute:
                sleep_time = 60 - (now - self.timestamps[0])
                time.sleep(sleep_time)

            # è®°å½•å½“å‰è¯·æ±‚æ—¶é—´æˆ³
            self.timestamps.append(now)

            return True
```

**å…³é”®è®¾è®¡**:
1. **Singleton æ¨¡å¼**: ç¡®ä¿å…¨å±€åªæœ‰ä¸€ä¸ªå®ä¾‹
2. **Semaphore å¹¶å‘æ§åˆ¶**: é™åˆ¶å¹¶å‘è¯·æ±‚æ•°
3. **æ»‘åŠ¨çª—å£**: ä½¿ç”¨ deque ç»´æŠ¤è¯·æ±‚æ—¶é—´æˆ³

---

## 5. å·¥å…·: Schema æ³¨å†Œè¡¨ (schema_registry.py)

### ä¸ºä»€ä¹ˆæ˜¯ 4 æ˜Ÿï¼Ÿ

å®ç°äº†**é›†ä¸­å¼ Schema ç®¡ç†**ï¼Œé˜²æ­¢æ•°æ®ä¸ä¸€è‡´ã€‚

```python
class SchemaRegistry:
    """
    Schema æ³¨å†Œè¡¨: é›†ä¸­å¼ç®¡ç†æ•°æ®é›† Schema
    """
    def __init__(self):
        self.schemas = {}  # {dataset_name: {column: type}}

    def register(self, dataset_name, schema):
        """æ³¨å†Œæ•°æ®é›† Schema"""
        self.schemas[dataset_name] = schema

    def get_schema(self, dataset_name):
        """è·å–æ•°æ®é›† Schema"""
        return self.schemas.get(dataset_name, {})

    def validate_columns(self, dataset_name, columns):
        """éªŒè¯åˆ—ååˆæ³•æ€§"""
        schema = self.get_schema(dataset_name)
        invalid_cols = [col for col in columns if col not in schema]
        if invalid_cols:
            raise ValueError(f"Invalid columns: {invalid_cols}")
        return True

    def get_column_type(self, dataset_name, column):
        """è·å–åˆ—ç±»å‹"""
        schema = self.get_schema(dataset_name)
        return schema.get(column, None)

# å…¨å±€å•ä¾‹
schema_registry = SchemaRegistry()
```

**ç”¨é€”**:
- **é˜²æ­¢åˆ—åå¹»è§‰**: LLM å¿…é¡»åŸºäºæ³¨å†Œçš„ Schema ç”Ÿæˆä»£ç 
- **ç±»å‹éªŒè¯**: éªŒè¯æ•°æ®ç±»å‹æ˜¯å¦åŒ¹é…
- **é›†ä¸­ç®¡ç†**: æ‰€æœ‰ Schema åœ¨ä¸€ä¸ªåœ°æ–¹ç®¡ç†

---

## è¿ç§»æ¸…å•

### ğŸ”´ P0 - å¿…é¡»è¿ç§»

- [ ] **ç»Ÿä¸€ LLM æ¥å£** - å¤šæ¨¡å‹æ”¯æŒ + çº¿ç¨‹é”
- [ ] **é€Ÿç‡é™åˆ¶å™¨** - é˜²æ­¢ Error 429

### ğŸŸ¡ P1 - å¼ºçƒˆæ¨è

- [ ] **Schema æ³¨å†Œè¡¨** - é›†ä¸­å¼ Schema ç®¡ç†
- [ ] **å˜é‡å¥‘çº¦ç³»ç»Ÿ** - å¤šé˜¶æ®µæ•°æ®ä¸€è‡´æ€§
- [ ] **ä»£ç å®ˆå«** - é¢„æ‰§è¡ŒéªŒè¯

### ğŸŸ¢ P2 - å¯é€‰è¿ç§»

- [ ] **æº¯å› æ¨ç†å¼•æ“** - è¯Šæ–­åˆ†æ
- [ ] **çº¢é˜Ÿæ‰¹è¯„å®¶** - è´¨é‡è¯„ä¼°
- [ ] **å™è¿°ç”Ÿæˆæ¨¡å—** - ç§‘ç ”å†™ä½œ
- [ ] **æŠ¥å‘Šç”Ÿæˆæ¡†æ¶** - å¤šæ ¼å¼æŠ¥å‘Š

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2026-01-24
**è¯¦ç»†åˆ†æ**: è§åŸå§‹æ–‡æ¡£ `../../LLM-MM-Agent/` ç›®å½•
